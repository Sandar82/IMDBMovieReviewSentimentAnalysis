{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "948c8117",
   "metadata": {},
   "source": [
    "# Import the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "a47ce64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import string\n",
    "import re\n",
    "from time import time\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ccfd2e",
   "metadata": {},
   "source": [
    "## Preprocess Text Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "9b549124",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Probably my all-time favorite movie, a story o...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I sure would like to see a resurrection of a u...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This show was an amazing, fresh &amp; innovative i...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Encouraged by the positive comments about this...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  I thought this was a wonderful way to spend ti...  positive\n",
       "1  Probably my all-time favorite movie, a story o...  positive\n",
       "2  I sure would like to see a resurrection of a u...  positive\n",
       "3  This show was an amazing, fresh & innovative i...  negative\n",
       "4  Encouraged by the positive comments about this...  negative"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"/Users/sandaraung/Documents/AI/IMDB_Dataset/IMDB_dataset.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "52fbd8ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 2)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a4ff00",
   "metadata": {},
   "source": [
    "## Subseting by the first 5000 due to data size is too big."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d44f5399",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.iloc[0:5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "8f1bac1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 2)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7adbee0",
   "metadata": {},
   "source": [
    "# Removal of Stopwords, Punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "26d5586f",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = nltk.corpus.stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c81aa498",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check punctuations\n",
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e6c5ff20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    # Remove punctuation\n",
    "    text = \"\".join([word for word in text if word not in string.punctuation])\n",
    "    \n",
    "    # Tokenization\n",
    "    tokens = re.split('\\W+', text)\n",
    "    \n",
    "    # Remove stopwords\n",
    "    text = [word for word in tokens if word not in stopwords]\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "cac58c4a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[thought, wonderful, way, spend, time, hot, su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Probably my all-time favorite movie, a story o...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[probably, alltime, favorite, movie, story, se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I sure would like to see a resurrection of a u...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[sure, would, like, see, resurrection, dated, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This show was an amazing, fresh &amp; innovative i...</td>\n",
       "      <td>negative</td>\n",
       "      <td>[show, amazing, fresh, innovative, idea, 70s, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Encouraged by the positive comments about this...</td>\n",
       "      <td>negative</td>\n",
       "      <td>[encouraged, positive, comments, film, looking...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment  \\\n",
       "0  I thought this was a wonderful way to spend ti...  positive   \n",
       "1  Probably my all-time favorite movie, a story o...  positive   \n",
       "2  I sure would like to see a resurrection of a u...  positive   \n",
       "3  This show was an amazing, fresh & innovative i...  negative   \n",
       "4  Encouraged by the positive comments about this...  negative   \n",
       "\n",
       "                                        review_clean  \n",
       "0  [thought, wonderful, way, spend, time, hot, su...  \n",
       "1  [probably, alltime, favorite, movie, story, se...  \n",
       "2  [sure, would, like, see, resurrection, dated, ...  \n",
       "3  [show, amazing, fresh, innovative, idea, 70s, ...  \n",
       "4  [encouraged, positive, comments, film, looking...  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['review_clean'] = df['review'].apply(lambda x: clean_text(x.lower()))\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e45b4b8",
   "metadata": {},
   "source": [
    "# Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "f6aac77a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review_clean</th>\n",
       "      <th>review_lemmatized</th>\n",
       "      <th>review_stemmed</th>\n",
       "      <th>review_len</th>\n",
       "      <th>punct%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[i, thought, this, was, a, wonderful, way, to,...</td>\n",
       "      <td>[thought, wonderful, way, spend, time, hot, su...</td>\n",
       "      <td>[thought, wonder, way, spend, time, hot, summe...</td>\n",
       "      <td>761</td>\n",
       "      <td>0.053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Probably my all-time favorite movie, a story o...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[probably, my, all, time, favorite, movie, a, ...</td>\n",
       "      <td>[probably, alltime, favorite, movie, story, se...</td>\n",
       "      <td>[probabl, alltim, favorit, movi, stori, selfle...</td>\n",
       "      <td>538</td>\n",
       "      <td>0.052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I sure would like to see a resurrection of a u...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[i, sure, would, like, to, see, a, resurrectio...</td>\n",
       "      <td>[sure, would, like, see, resurrection, dated, ...</td>\n",
       "      <td>[sure, would, like, see, resurrect, date, seah...</td>\n",
       "      <td>577</td>\n",
       "      <td>0.021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This show was an amazing, fresh &amp; innovative i...</td>\n",
       "      <td>negative</td>\n",
       "      <td>[this, show, was, an, amazing, fresh, innovati...</td>\n",
       "      <td>[show, amazing, fresh, innovative, idea, 70, f...</td>\n",
       "      <td>[show, amaz, fresh, innov, idea, 70, first, ai...</td>\n",
       "      <td>761</td>\n",
       "      <td>0.043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Encouraged by the positive comments about this...</td>\n",
       "      <td>negative</td>\n",
       "      <td>[encouraged, by, the, positive, comments, abou...</td>\n",
       "      <td>[encouraged, positive, comment, film, looking,...</td>\n",
       "      <td>[encourag, posit, comment, film, look, forward...</td>\n",
       "      <td>552</td>\n",
       "      <td>0.056</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment  \\\n",
       "0  I thought this was a wonderful way to spend ti...  positive   \n",
       "1  Probably my all-time favorite movie, a story o...  positive   \n",
       "2  I sure would like to see a resurrection of a u...  positive   \n",
       "3  This show was an amazing, fresh & innovative i...  negative   \n",
       "4  Encouraged by the positive comments about this...  negative   \n",
       "\n",
       "                                        review_clean  \\\n",
       "0  [i, thought, this, was, a, wonderful, way, to,...   \n",
       "1  [probably, my, all, time, favorite, movie, a, ...   \n",
       "2  [i, sure, would, like, to, see, a, resurrectio...   \n",
       "3  [this, show, was, an, amazing, fresh, innovati...   \n",
       "4  [encouraged, by, the, positive, comments, abou...   \n",
       "\n",
       "                                   review_lemmatized  \\\n",
       "0  [thought, wonderful, way, spend, time, hot, su...   \n",
       "1  [probably, alltime, favorite, movie, story, se...   \n",
       "2  [sure, would, like, see, resurrection, dated, ...   \n",
       "3  [show, amazing, fresh, innovative, idea, 70, f...   \n",
       "4  [encouraged, positive, comment, film, looking,...   \n",
       "\n",
       "                                      review_stemmed  review_len  punct%  \n",
       "0  [thought, wonder, way, spend, time, hot, summe...         761   0.053  \n",
       "1  [probabl, alltim, favorit, movi, stori, selfle...         538   0.052  \n",
       "2  [sure, would, like, see, resurrect, date, seah...         577   0.021  \n",
       "3  [show, amaz, fresh, innov, idea, 70, first, ai...         761   0.043  \n",
       "4  [encourag, posit, comment, film, look, forward...         552   0.056  "
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def tokenize(text):\n",
    "    tokens = re.split('\\W+', text)\n",
    "    return tokens\n",
    "\n",
    "df['review_clean']= df['review'].apply(lambda x: tokenize(x.lower()))\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d198e0a",
   "metadata": {},
   "source": [
    "## Lemmatizing and Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "20841918",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WordNet Lemmatizer\n",
    "wn = nltk.WordNetLemmatizer()\n",
    "\n",
    "# Porter stemmer\n",
    "ps = nltk.PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f446a777",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review_clean</th>\n",
       "      <th>review_lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[thought, wonderful, way, spend, time, hot, su...</td>\n",
       "      <td>[thought, wonderful, way, spend, time, hot, su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Probably my all-time favorite movie, a story o...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[probably, alltime, favorite, movie, story, se...</td>\n",
       "      <td>[probably, alltime, favorite, movie, story, se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I sure would like to see a resurrection of a u...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[sure, would, like, see, resurrection, dated, ...</td>\n",
       "      <td>[sure, would, like, see, resurrection, dated, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This show was an amazing, fresh &amp; innovative i...</td>\n",
       "      <td>negative</td>\n",
       "      <td>[show, amazing, fresh, innovative, idea, 70s, ...</td>\n",
       "      <td>[show, amazing, fresh, innovative, idea, 70, f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Encouraged by the positive comments about this...</td>\n",
       "      <td>negative</td>\n",
       "      <td>[encouraged, positive, comments, film, looking...</td>\n",
       "      <td>[encouraged, positive, comment, film, looking,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment  \\\n",
       "0  I thought this was a wonderful way to spend ti...  positive   \n",
       "1  Probably my all-time favorite movie, a story o...  positive   \n",
       "2  I sure would like to see a resurrection of a u...  positive   \n",
       "3  This show was an amazing, fresh & innovative i...  negative   \n",
       "4  Encouraged by the positive comments about this...  negative   \n",
       "\n",
       "                                        review_clean  \\\n",
       "0  [thought, wonderful, way, spend, time, hot, su...   \n",
       "1  [probably, alltime, favorite, movie, story, se...   \n",
       "2  [sure, would, like, see, resurrection, dated, ...   \n",
       "3  [show, amazing, fresh, innovative, idea, 70s, ...   \n",
       "4  [encouraged, positive, comments, film, looking...   \n",
       "\n",
       "                                   review_lemmatized  \n",
       "0  [thought, wonderful, way, spend, time, hot, su...  \n",
       "1  [probably, alltime, favorite, movie, story, se...  \n",
       "2  [sure, would, like, see, resurrection, dated, ...  \n",
       "3  [show, amazing, fresh, innovative, idea, 70, f...  \n",
       "4  [encouraged, positive, comment, film, looking,...  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def lemmatizing(tokenized_text):\n",
    "    text = [wn.lemmatize(word) for word in tokenized_text]\n",
    "    return text\n",
    "\n",
    "\n",
    "df['review_lemmatized'] = df['review_clean'].apply(lambda x: lemmatizing(x))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "547222bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review_clean</th>\n",
       "      <th>review_lemmatized</th>\n",
       "      <th>review_stemmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[thought, wonderful, way, spend, time, hot, su...</td>\n",
       "      <td>[thought, wonderful, way, spend, time, hot, su...</td>\n",
       "      <td>[thought, wonder, way, spend, time, hot, summe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Probably my all-time favorite movie, a story o...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[probably, alltime, favorite, movie, story, se...</td>\n",
       "      <td>[probably, alltime, favorite, movie, story, se...</td>\n",
       "      <td>[probabl, alltim, favorit, movi, stori, selfle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I sure would like to see a resurrection of a u...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[sure, would, like, see, resurrection, dated, ...</td>\n",
       "      <td>[sure, would, like, see, resurrection, dated, ...</td>\n",
       "      <td>[sure, would, like, see, resurrect, date, seah...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This show was an amazing, fresh &amp; innovative i...</td>\n",
       "      <td>negative</td>\n",
       "      <td>[show, amazing, fresh, innovative, idea, 70s, ...</td>\n",
       "      <td>[show, amazing, fresh, innovative, idea, 70, f...</td>\n",
       "      <td>[show, amaz, fresh, innov, idea, 70, first, ai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Encouraged by the positive comments about this...</td>\n",
       "      <td>negative</td>\n",
       "      <td>[encouraged, positive, comments, film, looking...</td>\n",
       "      <td>[encouraged, positive, comment, film, looking,...</td>\n",
       "      <td>[encourag, posit, comment, film, look, forward...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment  \\\n",
       "0  I thought this was a wonderful way to spend ti...  positive   \n",
       "1  Probably my all-time favorite movie, a story o...  positive   \n",
       "2  I sure would like to see a resurrection of a u...  positive   \n",
       "3  This show was an amazing, fresh & innovative i...  negative   \n",
       "4  Encouraged by the positive comments about this...  negative   \n",
       "\n",
       "                                        review_clean  \\\n",
       "0  [thought, wonderful, way, spend, time, hot, su...   \n",
       "1  [probably, alltime, favorite, movie, story, se...   \n",
       "2  [sure, would, like, see, resurrection, dated, ...   \n",
       "3  [show, amazing, fresh, innovative, idea, 70s, ...   \n",
       "4  [encouraged, positive, comments, film, looking...   \n",
       "\n",
       "                                   review_lemmatized  \\\n",
       "0  [thought, wonderful, way, spend, time, hot, su...   \n",
       "1  [probably, alltime, favorite, movie, story, se...   \n",
       "2  [sure, would, like, see, resurrection, dated, ...   \n",
       "3  [show, amazing, fresh, innovative, idea, 70, f...   \n",
       "4  [encouraged, positive, comment, film, looking,...   \n",
       "\n",
       "                                      review_stemmed  \n",
       "0  [thought, wonder, way, spend, time, hot, summe...  \n",
       "1  [probabl, alltim, favorit, movi, stori, selfle...  \n",
       "2  [sure, would, like, see, resurrect, date, seah...  \n",
       "3  [show, amaz, fresh, innov, idea, 70, first, ai...  \n",
       "4  [encourag, posit, comment, film, look, forward...  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def stemming(tokenized_text):\n",
    "    text = [ps.stem(word) for word in tokenized_text]\n",
    "    return text\n",
    "\n",
    "\n",
    "df['review_stemmed'] = df['review_clean'].apply(lambda x: stemming(x))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5252932b",
   "metadata": {},
   "source": [
    "## Apply  TFIDF Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "86ec1264",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vect = TfidfVectorizer(analyzer=clean_text)\n",
    "X_tfidf = tfidf_vect.fit_transform(df['review'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "0d84850b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 59137)\n",
      "['' '0' '00' ... 'ís' 'über' 'überwoman']\n"
     ]
    }
   ],
   "source": [
    "print(X_tfidf.shape)\n",
    "print(tfidf_vect.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "5a1dc96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_punctuation(text):\n",
    "    count = sum([1 for char in text if char in string.punctuation])\n",
    "    return round(count/(len(text) - text.count(\" \")), 3)\n",
    "\n",
    "\n",
    "df['review_len'] = df['review'].apply(lambda x: len(x) - x.count(\" \"))\n",
    "df['punct%'] = df['review'].apply(lambda x: count_punctuation(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "194d6729",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review_clean</th>\n",
       "      <th>review_lemmatized</th>\n",
       "      <th>review_stemmed</th>\n",
       "      <th>review_len</th>\n",
       "      <th>punct%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[thought, wonderful, way, spend, time, hot, su...</td>\n",
       "      <td>[thought, wonderful, way, spend, time, hot, su...</td>\n",
       "      <td>[thought, wonder, way, spend, time, hot, summe...</td>\n",
       "      <td>761</td>\n",
       "      <td>0.053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Probably my all-time favorite movie, a story o...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[probably, alltime, favorite, movie, story, se...</td>\n",
       "      <td>[probably, alltime, favorite, movie, story, se...</td>\n",
       "      <td>[probabl, alltim, favorit, movi, stori, selfle...</td>\n",
       "      <td>538</td>\n",
       "      <td>0.052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I sure would like to see a resurrection of a u...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[sure, would, like, see, resurrection, dated, ...</td>\n",
       "      <td>[sure, would, like, see, resurrection, dated, ...</td>\n",
       "      <td>[sure, would, like, see, resurrect, date, seah...</td>\n",
       "      <td>577</td>\n",
       "      <td>0.021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This show was an amazing, fresh &amp; innovative i...</td>\n",
       "      <td>negative</td>\n",
       "      <td>[show, amazing, fresh, innovative, idea, 70s, ...</td>\n",
       "      <td>[show, amazing, fresh, innovative, idea, 70, f...</td>\n",
       "      <td>[show, amaz, fresh, innov, idea, 70, first, ai...</td>\n",
       "      <td>761</td>\n",
       "      <td>0.043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Encouraged by the positive comments about this...</td>\n",
       "      <td>negative</td>\n",
       "      <td>[encouraged, positive, comments, film, looking...</td>\n",
       "      <td>[encouraged, positive, comment, film, looking,...</td>\n",
       "      <td>[encourag, posit, comment, film, look, forward...</td>\n",
       "      <td>552</td>\n",
       "      <td>0.056</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment  \\\n",
       "0  I thought this was a wonderful way to spend ti...  positive   \n",
       "1  Probably my all-time favorite movie, a story o...  positive   \n",
       "2  I sure would like to see a resurrection of a u...  positive   \n",
       "3  This show was an amazing, fresh & innovative i...  negative   \n",
       "4  Encouraged by the positive comments about this...  negative   \n",
       "\n",
       "                                        review_clean  \\\n",
       "0  [thought, wonderful, way, spend, time, hot, su...   \n",
       "1  [probably, alltime, favorite, movie, story, se...   \n",
       "2  [sure, would, like, see, resurrection, dated, ...   \n",
       "3  [show, amazing, fresh, innovative, idea, 70s, ...   \n",
       "4  [encouraged, positive, comments, film, looking...   \n",
       "\n",
       "                                   review_lemmatized  \\\n",
       "0  [thought, wonderful, way, spend, time, hot, su...   \n",
       "1  [probably, alltime, favorite, movie, story, se...   \n",
       "2  [sure, would, like, see, resurrection, dated, ...   \n",
       "3  [show, amazing, fresh, innovative, idea, 70, f...   \n",
       "4  [encouraged, positive, comment, film, looking,...   \n",
       "\n",
       "                                      review_stemmed  review_len  punct%  \n",
       "0  [thought, wonder, way, spend, time, hot, summe...         761   0.053  \n",
       "1  [probabl, alltim, favorit, movi, stori, selfle...         538   0.052  \n",
       "2  [sure, would, like, see, resurrect, date, seah...         577   0.021  \n",
       "3  [show, amaz, fresh, innov, idea, 70, first, ai...         761   0.043  \n",
       "4  [encourag, posit, comment, film, look, forward...         552   0.056  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35587b4d",
   "metadata": {},
   "source": [
    "## Preparing for features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "3bf386ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_features = pd.DataFrame(X_tfidf.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "e1894f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_features['review_len'] = df['review_len']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "54fdbb04",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_features['punct%'] = df['punct%']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "18f51c75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>59129</th>\n",
       "      <th>59130</th>\n",
       "      <th>59131</th>\n",
       "      <th>59132</th>\n",
       "      <th>59133</th>\n",
       "      <th>59134</th>\n",
       "      <th>59135</th>\n",
       "      <th>59136</th>\n",
       "      <th>review_len</th>\n",
       "      <th>punct%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>761</td>\n",
       "      <td>0.053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>538</td>\n",
       "      <td>0.052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>577</td>\n",
       "      <td>0.021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>761</td>\n",
       "      <td>0.043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>552</td>\n",
       "      <td>0.056</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 59139 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2    3    4    5    6    7    8    9  ...  59129  59130  59131  \\\n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0    0.0    0.0   \n",
       "1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0    0.0    0.0   \n",
       "2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0    0.0    0.0   \n",
       "3  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0    0.0    0.0   \n",
       "4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0    0.0    0.0   \n",
       "\n",
       "   59132  59133  59134  59135  59136  review_len  punct%  \n",
       "0    0.0    0.0    0.0    0.0    0.0         761   0.053  \n",
       "1    0.0    0.0    0.0    0.0    0.0         538   0.052  \n",
       "2    0.0    0.0    0.0    0.0    0.0         577   0.021  \n",
       "3    0.0    0.0    0.0    0.0    0.0         761   0.043  \n",
       "4    0.0    0.0    0.0    0.0    0.0         552   0.056  \n",
       "\n",
       "[5 rows x 59139 columns]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "dab7c6e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 59139)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "057abd44",
   "metadata": {},
   "source": [
    "## GridSearch CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "c719b775",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "5d8f170f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_features.columns = X_features.columns.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "22d502b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_features, df['sentiment'], test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "ba7718f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_RF(n_est, depth):\n",
    "    rf = RandomForestClassifier(n_estimators=n_est, max_depth=depth, n_jobs=-1)\n",
    "    rf_model = rf.fit(X_train, y_train)\n",
    "    y_pred = rf_model.predict(X_test)\n",
    "    precision, recall, fscore, support = score(y_test, y_pred, pos_label='positive', average='binary')\n",
    "    print('Est: {} / Depth: {} ---- Precision: {} / Recall: {} / Accuracy: {}'.format(\n",
    "        n_est, depth, round(precision, 3), round(recall, 3),\n",
    "        round((y_pred==y_test).sum() / len(y_pred), 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "5946a276",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Est: 10 / Depth: 10 ---- Precision: 0.658 / Recall: 0.757 / Accuracy: 0.687\n",
      "Est: 10 / Depth: 15 ---- Precision: 0.642 / Recall: 0.745 / Accuracy: 0.671\n",
      "Est: 10 / Depth: 25 ---- Precision: 0.699 / Recall: 0.73 / Accuracy: 0.713\n",
      "Est: 10 / Depth: None ---- Precision: 0.73 / Recall: 0.655 / Accuracy: 0.711\n",
      "Est: 40 / Depth: 10 ---- Precision: 0.739 / Recall: 0.844 / Accuracy: 0.777\n",
      "Est: 40 / Depth: 15 ---- Precision: 0.743 / Recall: 0.862 / Accuracy: 0.785\n",
      "Est: 40 / Depth: 25 ---- Precision: 0.779 / Recall: 0.821 / Accuracy: 0.797\n",
      "Est: 40 / Depth: None ---- Precision: 0.799 / Recall: 0.777 / Accuracy: 0.795\n",
      "Est: 80 / Depth: 10 ---- Precision: 0.755 / Recall: 0.889 / Accuracy: 0.804\n",
      "Est: 80 / Depth: 15 ---- Precision: 0.769 / Recall: 0.882 / Accuracy: 0.812\n",
      "Est: 80 / Depth: 25 ---- Precision: 0.79 / Recall: 0.859 / Accuracy: 0.819\n",
      "Est: 80 / Depth: None ---- Precision: 0.806 / Recall: 0.845 / Accuracy: 0.824\n"
     ]
    }
   ],
   "source": [
    "for n_est in [10, 40, 80]:\n",
    "    for depth in [10, 15, 25, None]:\n",
    "        train_RF(n_est, depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "91abbad4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review_clean</th>\n",
       "      <th>review_lemmatized</th>\n",
       "      <th>review_stemmed</th>\n",
       "      <th>review_len</th>\n",
       "      <th>punct%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[thought, wonderful, way, spend, time, hot, su...</td>\n",
       "      <td>[thought, wonderful, way, spend, time, hot, su...</td>\n",
       "      <td>[thought, wonder, way, spend, time, hot, summe...</td>\n",
       "      <td>761</td>\n",
       "      <td>0.053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Probably my all-time favorite movie, a story o...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[probably, alltime, favorite, movie, story, se...</td>\n",
       "      <td>[probably, alltime, favorite, movie, story, se...</td>\n",
       "      <td>[probabl, alltim, favorit, movi, stori, selfle...</td>\n",
       "      <td>538</td>\n",
       "      <td>0.052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I sure would like to see a resurrection of a u...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[sure, would, like, see, resurrection, dated, ...</td>\n",
       "      <td>[sure, would, like, see, resurrection, dated, ...</td>\n",
       "      <td>[sure, would, like, see, resurrect, date, seah...</td>\n",
       "      <td>577</td>\n",
       "      <td>0.021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This show was an amazing, fresh &amp; innovative i...</td>\n",
       "      <td>negative</td>\n",
       "      <td>[show, amazing, fresh, innovative, idea, 70s, ...</td>\n",
       "      <td>[show, amazing, fresh, innovative, idea, 70, f...</td>\n",
       "      <td>[show, amaz, fresh, innov, idea, 70, first, ai...</td>\n",
       "      <td>761</td>\n",
       "      <td>0.043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Encouraged by the positive comments about this...</td>\n",
       "      <td>negative</td>\n",
       "      <td>[encouraged, positive, comments, film, looking...</td>\n",
       "      <td>[encouraged, positive, comment, film, looking,...</td>\n",
       "      <td>[encourag, posit, comment, film, look, forward...</td>\n",
       "      <td>552</td>\n",
       "      <td>0.056</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment  \\\n",
       "0  I thought this was a wonderful way to spend ti...  positive   \n",
       "1  Probably my all-time favorite movie, a story o...  positive   \n",
       "2  I sure would like to see a resurrection of a u...  positive   \n",
       "3  This show was an amazing, fresh & innovative i...  negative   \n",
       "4  Encouraged by the positive comments about this...  negative   \n",
       "\n",
       "                                        review_clean  \\\n",
       "0  [thought, wonderful, way, spend, time, hot, su...   \n",
       "1  [probably, alltime, favorite, movie, story, se...   \n",
       "2  [sure, would, like, see, resurrection, dated, ...   \n",
       "3  [show, amazing, fresh, innovative, idea, 70s, ...   \n",
       "4  [encouraged, positive, comments, film, looking...   \n",
       "\n",
       "                                   review_lemmatized  \\\n",
       "0  [thought, wonderful, way, spend, time, hot, su...   \n",
       "1  [probably, alltime, favorite, movie, story, se...   \n",
       "2  [sure, would, like, see, resurrection, dated, ...   \n",
       "3  [show, amazing, fresh, innovative, idea, 70, f...   \n",
       "4  [encouraged, positive, comment, film, looking,...   \n",
       "\n",
       "                                      review_stemmed  review_len  punct%  \n",
       "0  [thought, wonder, way, spend, time, hot, summe...         761   0.053  \n",
       "1  [probabl, alltim, favorit, movi, stori, selfle...         538   0.052  \n",
       "2  [sure, would, like, see, resurrect, date, seah...         577   0.021  \n",
       "3  [show, amaz, fresh, innov, idea, 70, first, ai...         761   0.043  \n",
       "4  [encourag, posit, comment, film, look, forward...         552   0.056  "
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "9bb65f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = X_features\n",
    "labels = df[['sentiment']]\n",
    "\n",
    "models = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "2eb45bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_results(results):\n",
    "    print('BEST PARAMS: {}\\n'.format(results.best_params_))\n",
    "\n",
    "    means = results.cv_results_['mean_test_score']\n",
    "    stds = results.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, results.cv_results_['params']):\n",
    "        print('{} (+/-{}) for {}'.format(round(mean, 3), round(std * 2, 3), params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "233ebd2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(name, model, features, labels):\n",
    "    start = time()\n",
    "    pred = model.predict(features)\n",
    "    end = time()\n",
    "    accuracy = round(accuracy_score(labels, pred), 3)\n",
    "    precision = round(precision_score(labels, pred, average='micro'), 3)\n",
    "    recall = round(recall_score(labels, pred, average='micro'), 3)\n",
    "    print('{} -- Accuracy: {} / Precision: {} / Recall: {} / Latency: {}ms'.format(name,\n",
    "                                                                                   accuracy,\n",
    "                                                                                   precision,\n",
    "                                                                                   recall,\n",
    "                                                                                   round((end - start)*1000, 1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a45bc15",
   "metadata": {},
   "source": [
    "## RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "89ae3434",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEST PARAMS: {'max_depth': 25, 'n_estimators': 80}\n",
      "\n",
      "0.669 (+/-0.002) for {'max_depth': 10, 'n_estimators': 10}\n",
      "0.738 (+/-0.031) for {'max_depth': 10, 'n_estimators': 40}\n",
      "0.779 (+/-0.0) for {'max_depth': 10, 'n_estimators': 80}\n",
      "0.679 (+/-0.001) for {'max_depth': 15, 'n_estimators': 10}\n",
      "0.777 (+/-0.035) for {'max_depth': 15, 'n_estimators': 40}\n",
      "0.797 (+/-0.003) for {'max_depth': 15, 'n_estimators': 80}\n",
      "0.685 (+/-0.025) for {'max_depth': 25, 'n_estimators': 10}\n",
      "0.777 (+/-0.026) for {'max_depth': 25, 'n_estimators': 40}\n",
      "0.803 (+/-0.017) for {'max_depth': 25, 'n_estimators': 80}\n",
      "0.711 (+/-0.022) for {'max_depth': None, 'n_estimators': 10}\n",
      "0.776 (+/-0.002) for {'max_depth': None, 'n_estimators': 40}\n",
      "0.798 (+/-0.017) for {'max_depth': None, 'n_estimators': 80}\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier()\n",
    "param = {\n",
    "    'n_estimators': [10, 40, 80], \n",
    "    'max_depth': [10, 15, 25, None]\n",
    "}\n",
    "\n",
    "cv = GridSearchCV(rf, param, cv=2, n_jobs=-1)\n",
    "cv.fit(X_train, y_train)\n",
    "\n",
    "print_results(cv)\n",
    "models[\"RF\"] = cv.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac31481",
   "metadata": {},
   "source": [
    "# Gradient Boosting Classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "df4b4bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "006b3b6f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>80.597376</td>\n",
       "      <td>2.835463</td>\n",
       "      <td>5.127868</td>\n",
       "      <td>0.328629</td>\n",
       "      <td>0.1</td>\n",
       "      <td>8</td>\n",
       "      <td>40</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 8, 'n_esti...</td>\n",
       "      <td>0.766857</td>\n",
       "      <td>0.757714</td>\n",
       "      <td>0.762286</td>\n",
       "      <td>0.004571</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84.854071</td>\n",
       "      <td>2.462857</td>\n",
       "      <td>8.802279</td>\n",
       "      <td>0.894983</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5</td>\n",
       "      <td>40</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 5, 'n_esti...</td>\n",
       "      <td>0.768000</td>\n",
       "      <td>0.752000</td>\n",
       "      <td>0.760000</td>\n",
       "      <td>0.008000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>67.710104</td>\n",
       "      <td>1.549586</td>\n",
       "      <td>7.421038</td>\n",
       "      <td>0.285976</td>\n",
       "      <td>0.1</td>\n",
       "      <td>8</td>\n",
       "      <td>20</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 8, 'n_esti...</td>\n",
       "      <td>0.743429</td>\n",
       "      <td>0.743429</td>\n",
       "      <td>0.743429</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>76.756475</td>\n",
       "      <td>0.157767</td>\n",
       "      <td>11.299987</td>\n",
       "      <td>0.161977</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3</td>\n",
       "      <td>40</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 3, 'n_esti...</td>\n",
       "      <td>0.759429</td>\n",
       "      <td>0.725714</td>\n",
       "      <td>0.742571</td>\n",
       "      <td>0.016857</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>54.377445</td>\n",
       "      <td>0.197414</td>\n",
       "      <td>8.169328</td>\n",
       "      <td>0.286021</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 5, 'n_esti...</td>\n",
       "      <td>0.753143</td>\n",
       "      <td>0.716000</td>\n",
       "      <td>0.734571</td>\n",
       "      <td>0.018571</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "5      80.597376      2.835463         5.127868        0.328629   \n",
       "3      84.854071      2.462857         8.802279        0.894983   \n",
       "4      67.710104      1.549586         7.421038        0.285976   \n",
       "1      76.756475      0.157767        11.299987        0.161977   \n",
       "2      54.377445      0.197414         8.169328        0.286021   \n",
       "\n",
       "   param_learning_rate  param_max_depth  param_n_estimators  \\\n",
       "5                  0.1                8                  40   \n",
       "3                  0.1                5                  40   \n",
       "4                  0.1                8                  20   \n",
       "1                  0.1                3                  40   \n",
       "2                  0.1                5                  20   \n",
       "\n",
       "                                              params  split0_test_score  \\\n",
       "5  {'learning_rate': 0.1, 'max_depth': 8, 'n_esti...           0.766857   \n",
       "3  {'learning_rate': 0.1, 'max_depth': 5, 'n_esti...           0.768000   \n",
       "4  {'learning_rate': 0.1, 'max_depth': 8, 'n_esti...           0.743429   \n",
       "1  {'learning_rate': 0.1, 'max_depth': 3, 'n_esti...           0.759429   \n",
       "2  {'learning_rate': 0.1, 'max_depth': 5, 'n_esti...           0.753143   \n",
       "\n",
       "   split1_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "5           0.757714         0.762286        0.004571                1  \n",
       "3           0.752000         0.760000        0.008000                2  \n",
       "4           0.743429         0.743429        0.000000                3  \n",
       "1           0.725714         0.742571        0.016857                4  \n",
       "2           0.716000         0.734571        0.018571                5  "
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb = GradientBoostingClassifier()\n",
    "param = {\n",
    "    'n_estimators': [20,40], \n",
    "    'max_depth': [3,5,8],\n",
    "    'learning_rate': [0.1]\n",
    "}\n",
    "\n",
    "cv = GridSearchCV(gb, param, cv=2, n_jobs=-1)\n",
    "cv_fit = cv.fit(X_train, y_train)\n",
    "models[\"GB\"] = cv.best_estimator_\n",
    "pd.DataFrame(cv_fit.cv_results_).sort_values('mean_test_score', ascending=False)[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a1d146",
   "metadata": {},
   "source": [
    "## Final Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "a6f71f05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF -- Accuracy: 0.934 / Precision: 0.934 / Recall: 0.934 / Latency: 13790.0ms\n",
      "GB -- Accuracy: 0.907 / Precision: 0.907 / Recall: 0.907 / Latency: 24056.5ms\n"
     ]
    }
   ],
   "source": [
    "for name, model in models.items():\n",
    "    evaluate_model(name, model, features, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9fabb6c",
   "metadata": {},
   "source": [
    "# Report for best performance model\n",
    "\n",
    "***Analysis***\n",
    "\n",
    "Accuracy measures the proportion of correct predictions among the total number of cases processed. The RF model has an accuracy of 0.934, outperforming the GB model which has an accuracy of 0.907.\n",
    "\n",
    "Precision is the ratio of correctly predicted positive observations to the total predicted positives. The RF model shows a higher precision (0.934) compared to the GB model (0.907).\n",
    "\n",
    "Recall is the ratio of correctly predicted positive observations to the all observations in actual class. The RF model again outperforms with a recall of 0.934, whereas the GB model has a recall of 0.907.\n",
    "\n",
    "Latency refers to the time taken to make predictions. The RF model has a lower latency of 13790.0 ms, making it more efficient compared to the GB model which has a latency of 24056.5 ms.\n",
    "\n",
    "***Best Performance Model***\n",
    "\n",
    "Based on the evaluation metrics, the Random Forest (RF) model is the better-performing model compared to the Gradient Boosting (GB) model. It has higher accuracy, precision, and recall, and also operates with significantly lower latency. Therefore, the RF model is recommended for deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae76cc9f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
